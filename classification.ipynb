{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로이지스틱 회귀\n",
    "\n",
    "데이터를 입력했을때 해당 데이터의 결과를 특정 분류로 나누는 함수를 의미합니다. 그러므로 classification기법이라고도 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-3bea910e2757>:28: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0 1.71771 [[ 0.82313979  0.21220987  0.85243529]]\n",
      "20 0.677929 [[ 0.38241592 -0.2988987   0.3772774 ]]\n",
      "40 0.634545 [[ 0.09168912 -0.25736171  0.40237212]]\n",
      "60 0.596648 [[-0.18012159 -0.2223171   0.43033034]]\n",
      "80 0.563475 [[-0.43441379 -0.19201587  0.45943549]]\n",
      "100 0.534361 [[-0.67260182 -0.16528492  0.48865321]]\n",
      "120 0.508725 [[-0.896065   -0.14134493  0.51740283]]\n",
      "140 0.486066 [[-1.10611296 -0.1196714   0.54538661]]\n",
      "160 0.465955 [[-1.30396402 -0.09989989  0.57247418]]\n",
      "180 0.448027 [[-1.49073541 -0.08176592  0.59862912]]\n",
      "200 0.431974 [[-1.6674422  -0.06506765  0.62386525]]\n",
      "220 0.417537 [[-1.83499885 -0.04964348  0.6482206 ]]\n",
      "240 0.404495 [[-1.99422669 -0.03535955  0.67174411]]\n",
      "260 0.392664 [[-2.14586043 -0.02210165  0.69448709]]\n",
      "280 0.381887 [[-2.29055738 -0.00977041  0.71650016]]\n",
      "300 0.372033 [[ -2.42890573e+00   1.72145350e-03   7.37831354e-01]]\n",
      "320 0.362988 [[-2.56142926  0.0124513   0.75852466]]\n",
      "340 0.354657 [[-2.68859839  0.02248777  0.77862108]]\n",
      "360 0.346958 [[-2.81083322  0.03189215  0.79815799]]\n",
      "380 0.33982 [[-2.92851281  0.04071932  0.81716967]]\n",
      "400 0.333182 [[-3.04197645  0.04901832  0.83568752]]\n",
      "420 0.326992 [[-3.1515305   0.05683297  0.85374045]]\n",
      "440 0.321204 [[-3.2574513   0.06420275  0.87135488]]\n",
      "460 0.315779 [[-3.35998964  0.07116305  0.88855547]]\n",
      "480 0.310681 [[-3.45937181  0.07774569  0.90536469]]\n",
      "500 0.30588 [[-3.55580473  0.08397955  0.9218033 ]]\n",
      "520 0.301349 [[-3.64947629  0.08989058  0.93789083]]\n",
      "540 0.297064 [[-3.74055743  0.0955022   0.95364523]]\n",
      "560 0.293004 [[-3.82920575  0.10083579  0.96908313]]\n",
      "580 0.28915 [[-3.91556406  0.10591055  0.98422009]]\n",
      "600 0.285485 [[-3.99976468  0.11074416  0.99907047]]\n",
      "620 0.281994 [[-4.08192968  0.11535272  1.01364803]]\n",
      "640 0.278665 [[-4.16217089  0.11975084  1.02796531]]\n",
      "660 0.275484 [[-4.2405901   0.12395172  1.04203403]]\n",
      "680 0.272441 [[-4.31728363  0.12796776  1.05586517]]\n",
      "700 0.269525 [[-4.39234066  0.1318104   1.06946945]]\n",
      "720 0.266729 [[-4.46584272  0.13549     1.08285618]]\n",
      "740 0.264043 [[-4.53786707  0.13901609  1.09603465]]\n",
      "760 0.261461 [[-4.60848379  0.1423973   1.10901368]]\n",
      "780 0.258976 [[-4.67776012  0.14564206  1.12180138]]\n",
      "800 0.256581 [[-4.74575615  0.14875756  1.13440514]]\n",
      "820 0.254271 [[-4.81253099  0.15175109  1.14683223]]\n",
      "840 0.25204 [[-4.87813711  0.15462893  1.15908933]]\n",
      "860 0.249885 [[-4.94262695  0.15739749  1.17118311]]\n",
      "880 0.2478 [[-5.00604773  0.1600621   1.18311942]]\n",
      "900 0.245781 [[-5.06844378  0.16262808  1.19490409]]\n",
      "920 0.243825 [[-5.12985754  0.16510046  1.20654261]]\n",
      "940 0.241928 [[-5.19032812  0.16748352  1.21804035]]\n",
      "960 0.240088 [[-5.24989271  0.16978168  1.22940195]]\n",
      "980 0.2383 [[-5.30858707  0.17199916  1.24063194]]\n",
      "1000 0.236563 [[-5.36644411  0.17413954  1.25173485]]\n",
      "1020 0.234874 [[-5.42349434  0.17620634  1.26271498]]\n",
      "1040 0.23323 [[-5.47977066  0.1782033   1.2735765 ]]\n",
      "1060 0.23163 [[-5.53529692  0.18013279  1.28432274]]\n",
      "1080 0.23007 [[-5.59010172  0.18199827  1.29495764]]\n",
      "1100 0.22855 [[-5.64420938  0.18380237  1.30548453]]\n",
      "1120 0.227067 [[-5.69764471  0.18554763  1.31590688]]\n",
      "1140 0.225619 [[-5.75043106  0.18723671  1.32622766]]\n",
      "1160 0.224206 [[-5.80258894  0.18887177  1.33644986]]\n",
      "1180 0.222825 [[-5.85413885  0.19045514  1.34657669]]\n",
      "1200 0.221475 [[-5.90510035  0.19198865  1.35661042]]\n",
      "1220 0.220155 [[-5.95549297  0.19347467  1.3665539 ]]\n",
      "1240 0.218864 [[-6.00533581  0.19491515  1.37640965]]\n",
      "1260 0.2176 [[-6.05464363  0.19631147  1.38618016]]\n",
      "1280 0.216362 [[-6.10343409  0.19766568  1.39586771]]\n",
      "1300 0.215149 [[-6.15172148  0.19897908  1.40547454]]\n",
      "1320 0.213961 [[-6.19952106  0.20025331  1.41500258]]\n",
      "1340 0.212796 [[-6.24684763  0.20148996  1.42445409]]\n",
      "1360 0.211653 [[-6.29371452  0.20269041  1.43383086]]\n",
      "1380 0.210532 [[-6.3401351   0.20385593  1.44313514]]\n",
      "1400 0.209432 [[-6.38612127  0.20498765  1.4523685 ]]\n",
      "1420 0.208352 [[-6.43168402  0.20608678  1.46153259]]\n",
      "1440 0.20729 [[-6.47683668  0.20715459  1.4706291 ]]\n",
      "1460 0.206248 [[-6.52158833  0.2081922   1.4796598 ]]\n",
      "1480 0.205223 [[-6.56595325  0.20920078  1.48862624]]\n",
      "1500 0.204216 [[-6.60993671  0.21018104  1.49752975]]\n",
      "1520 0.203226 [[-6.65355158  0.21113399  1.50637197]]\n",
      "1540 0.202252 [[-6.69680595  0.2120606   1.51515412]]\n",
      "1560 0.201293 [[-6.7397089   0.21296179  1.52387762]]\n",
      "1580 0.200349 [[-6.78226995  0.21383846  1.53254366]]\n",
      "1600 0.199421 [[-6.82449675  0.21469118  1.54115379]]\n",
      "1620 0.198506 [[-6.86639738  0.21552093  1.54970884]]\n",
      "1640 0.197605 [[-6.90797949  0.21632843  1.55821013]]\n",
      "1660 0.196718 [[-6.9492507   0.21711433  1.56665885]]\n",
      "1680 0.195843 [[-6.99021864  0.21787947  1.57505596]]\n",
      "1700 0.194981 [[-7.03088951  0.21862426  1.58340263]]\n",
      "1720 0.194131 [[-7.07126904  0.21934931  1.59169972]]\n",
      "1740 0.193293 [[-7.11136723  0.22005561  1.59994853]]\n",
      "1760 0.192467 [[-7.15118742  0.22074343  1.60814989]]\n",
      "1780 0.191651 [[-7.19073582  0.22141309  1.61630464]]\n",
      "1800 0.190847 [[-7.23001909  0.22206558  1.62441373]]\n",
      "1820 0.190053 [[-7.26904297  0.22270143  1.63247776]]\n",
      "1840 0.189269 [[-7.30781269  0.22332087  1.64049804]]\n",
      "1860 0.188495 [[-7.34633255  0.22392446  1.64847505]]\n",
      "1880 0.187731 [[-7.38460922  0.22451271  1.65640974]]\n",
      "1900 0.186976 [[-7.42264652  0.22508609  1.66430259]]\n",
      "1920 0.186231 [[-7.4604497   0.22564498  1.67215478]]\n",
      "1940 0.185495 [[-7.49802303  0.22618981  1.67996669]]\n",
      "1960 0.184767 [[-7.5353713   0.22672103  1.68773913]]\n",
      "1980 0.184048 [[-7.57249928  0.22723904  1.69547284]]\n",
      "2000 0.183337 [[-7.60941029  0.22774409  1.70316827]]\n"
     ]
    }
   ],
   "source": [
    "#모두의 머신러닝의 로지스틱 회귀 코드를 참고함\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('train.txt', unpack=True, dtype='float32')\n",
    "x_data = xy[0:-1]\n",
    "y_data = xy[-1];\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1,len(x_data)], -1.0, 1.0))\n",
    "\n",
    "# Our hypothesis\n",
    "h = tf.matmul(W, X)\n",
    "hypothesis = tf.div(1., 1.+tf.exp(-h))\n",
    "\n",
    "# cost function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "# Minimize\n",
    "a = tf.Variable(0.1) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Before starting, initialize the variables. We will 'run' this first.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Fit the line.\n",
    "for step in range(2001):\n",
    "    sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 20 == 0:\n",
    "        print (step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 테스트하기\n",
    "\n",
    "학습을 마친 후 새로운 데이터에 대해 정확한 분류가 되는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "[[False]]\n",
      "[[ True]]\n",
      "[[False  True]]\n"
     ]
    }
   ],
   "source": [
    "print ('---------------------------------------')\n",
    "# study_hour attendance\n",
    "print (sess.run(hypothesis, feed_dict={X:[[1], [2], [2]]}) > 0.5)\n",
    "print (sess.run(hypothesis, feed_dict={X:[[1], [5], [5]]}) > 0.5)\n",
    "\n",
    "print (sess.run(hypothesis, feed_dict={X:[[1, 1], [4, 3], [3, 5]]}) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료\n",
    "\n",
    "(타이틀,저자,자료명,출처)\n",
    "1. 모두의 머신러닝,김성훈,로지스터 회귀,https://hunkim.github.io/ml/\n",
    "2. 임베디드 개발자의 TensorFlow 학습하기,jybaek,로지스터 회귀,https://www.gitbook.com/book/jybaek/ml/details\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
